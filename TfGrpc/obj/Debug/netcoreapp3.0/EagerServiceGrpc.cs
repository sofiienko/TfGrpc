// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: tensorflow/core/protobuf/eager_service.proto
// </auto-generated>
#pragma warning disable 0414, 1591
#region Designer generated code

using grpc = global::Grpc.Core;

namespace Tensorflow.Eager {
  /// <summary>
  /////////////////////////////////////////////////////////////////////////////////
  ///
  /// Eager Service defines a TensorFlow service that executes operations eagerly
  /// on a set of local devices, on behalf of a remote Eager executor.
  ///
  /// The service impl will keep track of the various clients and devices it has
  /// access to and allows the client to enqueue ops on any devices that it is able
  /// to access and schedule data transfers from/to any of the peers.
  ///
  /// A client can generate multiple contexts to be able to independently execute
  /// operations, but cannot share data between the two contexts.
  ///
  /// NOTE: Even though contexts generated by clients should be independent, the
  /// lower level tensorflow execution engine is not, so they might share some data
  /// (e.g. a Device's ResourceMgr).
  ///
  /////////////////////////////////////////////////////////////////////////////////
  /// </summary>
  public static partial class EagerService
  {
    static readonly string __ServiceName = "tensorflow.eager.EagerService";

    static readonly grpc::Marshaller<global::Tensorflow.Eager.CreateContextRequest> __Marshaller_tensorflow_eager_CreateContextRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.CreateContextRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.CreateContextResponse> __Marshaller_tensorflow_eager_CreateContextResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.CreateContextResponse.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.UpdateContextRequest> __Marshaller_tensorflow_eager_UpdateContextRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.UpdateContextRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.UpdateContextResponse> __Marshaller_tensorflow_eager_UpdateContextResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.UpdateContextResponse.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.EnqueueRequest> __Marshaller_tensorflow_eager_EnqueueRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.EnqueueRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.EnqueueResponse> __Marshaller_tensorflow_eager_EnqueueResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.EnqueueResponse.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.WaitQueueDoneRequest> __Marshaller_tensorflow_eager_WaitQueueDoneRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.WaitQueueDoneRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.WaitQueueDoneResponse> __Marshaller_tensorflow_eager_WaitQueueDoneResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.WaitQueueDoneResponse.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.KeepAliveRequest> __Marshaller_tensorflow_eager_KeepAliveRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.KeepAliveRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.KeepAliveResponse> __Marshaller_tensorflow_eager_KeepAliveResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.KeepAliveResponse.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.CloseContextRequest> __Marshaller_tensorflow_eager_CloseContextRequest = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.CloseContextRequest.Parser.ParseFrom);
    static readonly grpc::Marshaller<global::Tensorflow.Eager.CloseContextResponse> __Marshaller_tensorflow_eager_CloseContextResponse = grpc::Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Tensorflow.Eager.CloseContextResponse.Parser.ParseFrom);

    static readonly grpc::Method<global::Tensorflow.Eager.CreateContextRequest, global::Tensorflow.Eager.CreateContextResponse> __Method_CreateContext = new grpc::Method<global::Tensorflow.Eager.CreateContextRequest, global::Tensorflow.Eager.CreateContextResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "CreateContext",
        __Marshaller_tensorflow_eager_CreateContextRequest,
        __Marshaller_tensorflow_eager_CreateContextResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.UpdateContextRequest, global::Tensorflow.Eager.UpdateContextResponse> __Method_UpdateContext = new grpc::Method<global::Tensorflow.Eager.UpdateContextRequest, global::Tensorflow.Eager.UpdateContextResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "UpdateContext",
        __Marshaller_tensorflow_eager_UpdateContextRequest,
        __Marshaller_tensorflow_eager_UpdateContextResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse> __Method_Enqueue = new grpc::Method<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "Enqueue",
        __Marshaller_tensorflow_eager_EnqueueRequest,
        __Marshaller_tensorflow_eager_EnqueueResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse> __Method_StreamingEnqueue = new grpc::Method<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse>(
        grpc::MethodType.DuplexStreaming,
        __ServiceName,
        "StreamingEnqueue",
        __Marshaller_tensorflow_eager_EnqueueRequest,
        __Marshaller_tensorflow_eager_EnqueueResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.WaitQueueDoneRequest, global::Tensorflow.Eager.WaitQueueDoneResponse> __Method_WaitQueueDone = new grpc::Method<global::Tensorflow.Eager.WaitQueueDoneRequest, global::Tensorflow.Eager.WaitQueueDoneResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "WaitQueueDone",
        __Marshaller_tensorflow_eager_WaitQueueDoneRequest,
        __Marshaller_tensorflow_eager_WaitQueueDoneResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.KeepAliveRequest, global::Tensorflow.Eager.KeepAliveResponse> __Method_KeepAlive = new grpc::Method<global::Tensorflow.Eager.KeepAliveRequest, global::Tensorflow.Eager.KeepAliveResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "KeepAlive",
        __Marshaller_tensorflow_eager_KeepAliveRequest,
        __Marshaller_tensorflow_eager_KeepAliveResponse);

    static readonly grpc::Method<global::Tensorflow.Eager.CloseContextRequest, global::Tensorflow.Eager.CloseContextResponse> __Method_CloseContext = new grpc::Method<global::Tensorflow.Eager.CloseContextRequest, global::Tensorflow.Eager.CloseContextResponse>(
        grpc::MethodType.Unary,
        __ServiceName,
        "CloseContext",
        __Marshaller_tensorflow_eager_CloseContextRequest,
        __Marshaller_tensorflow_eager_CloseContextResponse);

    /// <summary>Service descriptor</summary>
    public static global::Google.Protobuf.Reflection.ServiceDescriptor Descriptor
    {
      get { return global::Tensorflow.Eager.EagerServiceReflection.Descriptor.Services[0]; }
    }

    /// <summary>Client for EagerService</summary>
    public partial class EagerServiceClient : grpc::ClientBase<EagerServiceClient>
    {
      /// <summary>Creates a new client for EagerService</summary>
      /// <param name="channel">The channel to use to make remote calls.</param>
      public EagerServiceClient(grpc::ChannelBase channel) : base(channel)
      {
      }
      /// <summary>Creates a new client for EagerService that uses a custom <c>CallInvoker</c>.</summary>
      /// <param name="callInvoker">The callInvoker to use to make remote calls.</param>
      public EagerServiceClient(grpc::CallInvoker callInvoker) : base(callInvoker)
      {
      }
      /// <summary>Protected parameterless constructor to allow creation of test doubles.</summary>
      protected EagerServiceClient() : base()
      {
      }
      /// <summary>Protected constructor to allow creation of configured clients.</summary>
      /// <param name="configuration">The client configuration.</param>
      protected EagerServiceClient(ClientBaseConfiguration configuration) : base(configuration)
      {
      }

      /// <summary>
      /// This initializes the worker, informing it about the other workers in the
      /// cluster and exchanging authentication tokens which will be used in all
      /// other RPCs to detect whether the worker has restarted.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.CreateContextResponse CreateContext(global::Tensorflow.Eager.CreateContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateContext(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This initializes the worker, informing it about the other workers in the
      /// cluster and exchanging authentication tokens which will be used in all
      /// other RPCs to detect whether the worker has restarted.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.CreateContextResponse CreateContext(global::Tensorflow.Eager.CreateContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_CreateContext, null, options, request);
      }
      /// <summary>
      /// This initializes the worker, informing it about the other workers in the
      /// cluster and exchanging authentication tokens which will be used in all
      /// other RPCs to detect whether the worker has restarted.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.CreateContextResponse> CreateContextAsync(global::Tensorflow.Eager.CreateContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CreateContextAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This initializes the worker, informing it about the other workers in the
      /// cluster and exchanging authentication tokens which will be used in all
      /// other RPCs to detect whether the worker has restarted.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.CreateContextResponse> CreateContextAsync(global::Tensorflow.Eager.CreateContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_CreateContext, null, options, request);
      }
      /// <summary>
      /// This updates the eager context on an existing worker when updating the set
      /// of servers in a distributed eager cluster.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.UpdateContextResponse UpdateContext(global::Tensorflow.Eager.UpdateContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return UpdateContext(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This updates the eager context on an existing worker when updating the set
      /// of servers in a distributed eager cluster.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.UpdateContextResponse UpdateContext(global::Tensorflow.Eager.UpdateContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_UpdateContext, null, options, request);
      }
      /// <summary>
      /// This updates the eager context on an existing worker when updating the set
      /// of servers in a distributed eager cluster.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.UpdateContextResponse> UpdateContextAsync(global::Tensorflow.Eager.UpdateContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return UpdateContextAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This updates the eager context on an existing worker when updating the set
      /// of servers in a distributed eager cluster.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.UpdateContextResponse> UpdateContextAsync(global::Tensorflow.Eager.UpdateContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_UpdateContext, null, options, request);
      }
      /// <summary>
      /// This takes a list of Execute and DeleteTensorHandle operations and enqueues
      /// (in async mode) or executes (in sync mode) them on the remote server.
      /// All outputs of ops which were not explicitly deleted with
      /// DeleteTensorHandle entries will be assumed to be alive and are usable by
      /// future calls to Enqueue.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.EnqueueResponse Enqueue(global::Tensorflow.Eager.EnqueueRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return Enqueue(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This takes a list of Execute and DeleteTensorHandle operations and enqueues
      /// (in async mode) or executes (in sync mode) them on the remote server.
      /// All outputs of ops which were not explicitly deleted with
      /// DeleteTensorHandle entries will be assumed to be alive and are usable by
      /// future calls to Enqueue.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.EnqueueResponse Enqueue(global::Tensorflow.Eager.EnqueueRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_Enqueue, null, options, request);
      }
      /// <summary>
      /// This takes a list of Execute and DeleteTensorHandle operations and enqueues
      /// (in async mode) or executes (in sync mode) them on the remote server.
      /// All outputs of ops which were not explicitly deleted with
      /// DeleteTensorHandle entries will be assumed to be alive and are usable by
      /// future calls to Enqueue.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.EnqueueResponse> EnqueueAsync(global::Tensorflow.Eager.EnqueueRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return EnqueueAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// This takes a list of Execute and DeleteTensorHandle operations and enqueues
      /// (in async mode) or executes (in sync mode) them on the remote server.
      /// All outputs of ops which were not explicitly deleted with
      /// DeleteTensorHandle entries will be assumed to be alive and are usable by
      /// future calls to Enqueue.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.EnqueueResponse> EnqueueAsync(global::Tensorflow.Eager.EnqueueRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_Enqueue, null, options, request);
      }
      /// <summary>
      /// A streaming version of Enqueue.
      /// Current server implementation sends one response per received request.
      /// The benefit for using a streaming version is that subsequent requests
      /// can be sent without waiting for a response to the previous request. This
      /// synchronization is required in the regular Enqueue call because gRPC does
      /// not guarantee to preserve request order.
      /// </summary>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncDuplexStreamingCall<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse> StreamingEnqueue(grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return StreamingEnqueue(new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// A streaming version of Enqueue.
      /// Current server implementation sends one response per received request.
      /// The benefit for using a streaming version is that subsequent requests
      /// can be sent without waiting for a response to the previous request. This
      /// synchronization is required in the regular Enqueue call because gRPC does
      /// not guarantee to preserve request order.
      /// </summary>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncDuplexStreamingCall<global::Tensorflow.Eager.EnqueueRequest, global::Tensorflow.Eager.EnqueueResponse> StreamingEnqueue(grpc::CallOptions options)
      {
        return CallInvoker.AsyncDuplexStreamingCall(__Method_StreamingEnqueue, null, options);
      }
      /// <summary>
      /// Takes a set of op IDs and waits until those ops are done. Returns any error
      /// in the stream so far.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.WaitQueueDoneResponse WaitQueueDone(global::Tensorflow.Eager.WaitQueueDoneRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return WaitQueueDone(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Takes a set of op IDs and waits until those ops are done. Returns any error
      /// in the stream so far.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.WaitQueueDoneResponse WaitQueueDone(global::Tensorflow.Eager.WaitQueueDoneRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_WaitQueueDone, null, options, request);
      }
      /// <summary>
      /// Takes a set of op IDs and waits until those ops are done. Returns any error
      /// in the stream so far.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.WaitQueueDoneResponse> WaitQueueDoneAsync(global::Tensorflow.Eager.WaitQueueDoneRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return WaitQueueDoneAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Takes a set of op IDs and waits until those ops are done. Returns any error
      /// in the stream so far.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.WaitQueueDoneResponse> WaitQueueDoneAsync(global::Tensorflow.Eager.WaitQueueDoneRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_WaitQueueDone, null, options, request);
      }
      /// <summary>
      /// Contexts are always created with a deadline and no RPCs within a deadline
      /// will trigger a context garbage collection. KeepAlive calls can be used to
      /// delay this. It can also be used to validate the existance of a context ID
      /// on remote eager worker. If the context is on remote worker, return the same
      /// ID and the current context view ID. This is useful for checking if the
      /// remote worker (potentially with the same task name and hostname / port) is
      /// replaced with a new process.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.KeepAliveResponse KeepAlive(global::Tensorflow.Eager.KeepAliveRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return KeepAlive(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Contexts are always created with a deadline and no RPCs within a deadline
      /// will trigger a context garbage collection. KeepAlive calls can be used to
      /// delay this. It can also be used to validate the existance of a context ID
      /// on remote eager worker. If the context is on remote worker, return the same
      /// ID and the current context view ID. This is useful for checking if the
      /// remote worker (potentially with the same task name and hostname / port) is
      /// replaced with a new process.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.KeepAliveResponse KeepAlive(global::Tensorflow.Eager.KeepAliveRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_KeepAlive, null, options, request);
      }
      /// <summary>
      /// Contexts are always created with a deadline and no RPCs within a deadline
      /// will trigger a context garbage collection. KeepAlive calls can be used to
      /// delay this. It can also be used to validate the existance of a context ID
      /// on remote eager worker. If the context is on remote worker, return the same
      /// ID and the current context view ID. This is useful for checking if the
      /// remote worker (potentially with the same task name and hostname / port) is
      /// replaced with a new process.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.KeepAliveResponse> KeepAliveAsync(global::Tensorflow.Eager.KeepAliveRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return KeepAliveAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Contexts are always created with a deadline and no RPCs within a deadline
      /// will trigger a context garbage collection. KeepAlive calls can be used to
      /// delay this. It can also be used to validate the existance of a context ID
      /// on remote eager worker. If the context is on remote worker, return the same
      /// ID and the current context view ID. This is useful for checking if the
      /// remote worker (potentially with the same task name and hostname / port) is
      /// replaced with a new process.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.KeepAliveResponse> KeepAliveAsync(global::Tensorflow.Eager.KeepAliveRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_KeepAlive, null, options, request);
      }
      /// <summary>
      /// Closes the context. No calls to other methods using the existing context ID
      /// are valid after this.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.CloseContextResponse CloseContext(global::Tensorflow.Eager.CloseContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CloseContext(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Closes the context. No calls to other methods using the existing context ID
      /// are valid after this.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The response received from the server.</returns>
      public virtual global::Tensorflow.Eager.CloseContextResponse CloseContext(global::Tensorflow.Eager.CloseContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_CloseContext, null, options, request);
      }
      /// <summary>
      /// Closes the context. No calls to other methods using the existing context ID
      /// are valid after this.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="headers">The initial metadata to send with the call. This parameter is optional.</param>
      /// <param name="deadline">An optional deadline for the call. The call will be cancelled if deadline is hit.</param>
      /// <param name="cancellationToken">An optional token for canceling the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.CloseContextResponse> CloseContextAsync(global::Tensorflow.Eager.CloseContextRequest request, grpc::Metadata headers = null, global::System.DateTime? deadline = null, global::System.Threading.CancellationToken cancellationToken = default(global::System.Threading.CancellationToken))
      {
        return CloseContextAsync(request, new grpc::CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      /// Closes the context. No calls to other methods using the existing context ID
      /// are valid after this.
      /// </summary>
      /// <param name="request">The request to send to the server.</param>
      /// <param name="options">The options for the call.</param>
      /// <returns>The call object.</returns>
      public virtual grpc::AsyncUnaryCall<global::Tensorflow.Eager.CloseContextResponse> CloseContextAsync(global::Tensorflow.Eager.CloseContextRequest request, grpc::CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_CloseContext, null, options, request);
      }
      /// <summary>Creates a new instance of client from given <c>ClientBaseConfiguration</c>.</summary>
      protected override EagerServiceClient NewInstance(ClientBaseConfiguration configuration)
      {
        return new EagerServiceClient(configuration);
      }
    }

  }
}
#endregion
