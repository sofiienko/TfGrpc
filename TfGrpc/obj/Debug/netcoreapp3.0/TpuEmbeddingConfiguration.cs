// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: tensorflow/core/protobuf/tpu/tpu_embedding_configuration.proto
// </auto-generated>
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Tensorflow.Tpu {

  /// <summary>Holder for reflection information generated from tensorflow/core/protobuf/tpu/tpu_embedding_configuration.proto</summary>
  public static partial class TpuEmbeddingConfigurationReflection {

    #region Descriptor
    /// <summary>File descriptor for tensorflow/core/protobuf/tpu/tpu_embedding_configuration.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static TpuEmbeddingConfigurationReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Cj50ZW5zb3JmbG93L2NvcmUvcHJvdG9idWYvdHB1L3RwdV9lbWJlZGRpbmdf",
            "Y29uZmlndXJhdGlvbi5wcm90bxIOdGVuc29yZmxvdy50cHUaOnRlbnNvcmZs",
            "b3cvY29yZS9wcm90b2J1Zi90cHUvb3B0aW1pemF0aW9uX3BhcmFtZXRlcnMu",
            "cHJvdG8aPnRlbnNvcmZsb3cvY29yZS9wcm90b2J1Zi90cHUvdHB1X2VtYmVk",
            "ZGluZ19vdXRwdXRfbGF5b3V0LnByb3RvIu0FChlUUFVFbWJlZGRpbmdDb25m",
            "aWd1cmF0aW9uElMKEHRhYmxlX2Rlc2NyaXB0b3IYASADKAsyOS50ZW5zb3Jm",
            "bG93LnRwdS5UUFVFbWJlZGRpbmdDb25maWd1cmF0aW9uLlRhYmxlRGVzY3Jp",
            "cHRvchI8CgRtb2RlGAIgASgOMi4udGVuc29yZmxvdy50cHUuVFBVRW1iZWRk",
            "aW5nQ29uZmlndXJhdGlvbi5Nb2RlEiIKGmJhdGNoX3NpemVfcGVyX3RlbnNv",
            "cl9jb3JlGAMgASgFEhEKCW51bV9ob3N0cxgEIAEoBRIYChBudW1fdGVuc29y",
            "X2NvcmVzGAUgASgFElUKEXNoYXJkaW5nX3N0cmF0ZWd5GAYgASgOMjoudGVu",
            "c29yZmxvdy50cHUuVFBVRW1iZWRkaW5nQ29uZmlndXJhdGlvbi5TaGFyZGlu",
            "Z1N0cmF0ZWd5EisKI3BpcGVsaW5lX2V4ZWN1dGlvbl93aXRoX3RlbnNvcl9j",
            "b3JlGAcgASgIEj8KDW91dHB1dF9sYXlvdXQYCCABKAsyKC50ZW5zb3JmbG93",
            "LnRwdS5UUFVFbWJlZGRpbmdPdXRwdXRMYXlvdXQaqgEKD1RhYmxlRGVzY3Jp",
            "cHRvchIMCgRuYW1lGAEgASgJEhcKD3ZvY2FidWxhcnlfc2l6ZRgCIAEoBRIR",
            "CglkaW1lbnNpb24YAyABKAUSFAoMbnVtX2ZlYXR1cmVzGAQgASgFEkcKF29w",
            "dGltaXphdGlvbl9wYXJhbWV0ZXJzGAUgASgLMiYudGVuc29yZmxvdy50cHUu",
            "T3B0aW1pemF0aW9uUGFyYW1ldGVycyJMCgRNb2RlEg8KC1VOU1BFQ0lGSUVE",
            "EAASDQoJSU5GRVJFTkNFEAESDAoIVFJBSU5JTkcQAhIWChJCQUNLV0FSRF9Q",
            "QVNTX09OTFkQAyIsChBTaGFyZGluZ1N0cmF0ZWd5Eg8KC0RJVl9ERUZBVUxU",
            "EAASBwoDTU9EEAFiBnByb3RvMw=="));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Tensorflow.Tpu.OptimizationParametersReflection.Descriptor, global::Tensorflow.Tpu.TpuEmbeddingOutputLayoutReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(null, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.Tpu.TPUEmbeddingConfiguration), global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Parser, new[]{ "TableDescriptor", "Mode", "BatchSizePerTensorCore", "NumHosts", "NumTensorCores", "ShardingStrategy", "PipelineExecutionWithTensorCore", "OutputLayout" }, null, new[]{ typeof(global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.Mode), typeof(global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.ShardingStrategy) }, new pbr::GeneratedClrTypeInfo[] { new pbr::GeneratedClrTypeInfo(typeof(global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor), global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor.Parser, new[]{ "Name", "VocabularySize", "Dimension", "NumFeatures", "OptimizationParameters" }, null, null, null)})
          }));
    }
    #endregion

  }
  #region Messages
  public sealed partial class TPUEmbeddingConfiguration : pb::IMessage<TPUEmbeddingConfiguration> {
    private static readonly pb::MessageParser<TPUEmbeddingConfiguration> _parser = new pb::MessageParser<TPUEmbeddingConfiguration>(() => new TPUEmbeddingConfiguration());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<TPUEmbeddingConfiguration> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Tensorflow.Tpu.TpuEmbeddingConfigurationReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public TPUEmbeddingConfiguration() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public TPUEmbeddingConfiguration(TPUEmbeddingConfiguration other) : this() {
      tableDescriptor_ = other.tableDescriptor_.Clone();
      mode_ = other.mode_;
      batchSizePerTensorCore_ = other.batchSizePerTensorCore_;
      numHosts_ = other.numHosts_;
      numTensorCores_ = other.numTensorCores_;
      shardingStrategy_ = other.shardingStrategy_;
      pipelineExecutionWithTensorCore_ = other.pipelineExecutionWithTensorCore_;
      outputLayout_ = other.outputLayout_ != null ? other.outputLayout_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public TPUEmbeddingConfiguration Clone() {
      return new TPUEmbeddingConfiguration(this);
    }

    /// <summary>Field number for the "table_descriptor" field.</summary>
    public const int TableDescriptorFieldNumber = 1;
    private static readonly pb::FieldCodec<global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor> _repeated_tableDescriptor_codec
        = pb::FieldCodec.ForMessage(10, global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor.Parser);
    private readonly pbc::RepeatedField<global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor> tableDescriptor_ = new pbc::RepeatedField<global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor>();
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.TableDescriptor> TableDescriptor {
      get { return tableDescriptor_; }
    }

    /// <summary>Field number for the "mode" field.</summary>
    public const int ModeFieldNumber = 2;
    private global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.Mode mode_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.Mode Mode {
      get { return mode_; }
      set {
        mode_ = value;
      }
    }

    /// <summary>Field number for the "batch_size_per_tensor_core" field.</summary>
    public const int BatchSizePerTensorCoreFieldNumber = 3;
    private int batchSizePerTensorCore_;
    /// <summary>
    /// Number of samples in each batch of embedding layer activations sent to
    /// the TensorCore.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int BatchSizePerTensorCore {
      get { return batchSizePerTensorCore_; }
      set {
        batchSizePerTensorCore_ = value;
      }
    }

    /// <summary>Field number for the "num_hosts" field.</summary>
    public const int NumHostsFieldNumber = 4;
    private int numHosts_;
    /// <summary>
    /// Number of TPU hosts used for inference/training.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int NumHosts {
      get { return numHosts_; }
      set {
        numHosts_ = value;
      }
    }

    /// <summary>Field number for the "num_tensor_cores" field.</summary>
    public const int NumTensorCoresFieldNumber = 5;
    private int numTensorCores_;
    /// <summary>
    /// Number of TensorCore used for inference/training.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int NumTensorCores {
      get { return numTensorCores_; }
      set {
        numTensorCores_ = value;
      }
    }

    /// <summary>Field number for the "sharding_strategy" field.</summary>
    public const int ShardingStrategyFieldNumber = 6;
    private global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.ShardingStrategy shardingStrategy_ = 0;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.ShardingStrategy ShardingStrategy {
      get { return shardingStrategy_; }
      set {
        shardingStrategy_ = value;
      }
    }

    /// <summary>Field number for the "pipeline_execution_with_tensor_core" field.</summary>
    public const int PipelineExecutionWithTensorCoreFieldNumber = 7;
    private bool pipelineExecutionWithTensorCore_;
    /// <summary>
    /// This parameter determines if the execution of the sparse core will be
    /// pipelined with that of the TensorCore. This parameter only affects results
    /// when mode=TRAINING. If mode=INFERENCE or BACKWARD_PASS_ONLY, this parameter
    /// does not affect execution and hence, is a don't care value.
    ///
    /// false: The execution of the sparse core is not pipelined with that of the
    /// TensorCore. The forward pass of every step on the sparse core is executed
    /// only after the backward pass of the previous step is complete. And the
    /// backward pass on the sparse core is executed only after the embedding
    /// gradients have been computed on the TensorCore on every step. This ensures
    /// that the activations on every step observe the gradient updates from the
    /// previous step on both the sparse core and the TensorCore.
    ///
    /// true: The execution of the sparse core is pipelined with that of the
    /// TensorCore. The forward pass of every step on the sparse core can be
    /// executed after the forward pass of the previous step is complete without
    /// waiting for the backward pass. This improves the utilization of the sparse
    /// core allowing it to process step N+1 while the embedding gradients for step
    /// N are computed on the TensorCore. The backward pass of every step on the
    /// sparse core is executed directly after the forward pass for the next step
    /// is complete. The drawback is that embedding activations for step N+1 do not
    /// observe the embedding gradient updates from step N. This could affect model
    /// quality if step N and N+1 involve the same set of embedding IDs. However,
    /// since the embedding updates are sparse, this is generally not considered a
    /// problem.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool PipelineExecutionWithTensorCore {
      get { return pipelineExecutionWithTensorCore_; }
      set {
        pipelineExecutionWithTensorCore_ = value;
      }
    }

    /// <summary>Field number for the "output_layout" field.</summary>
    public const int OutputLayoutFieldNumber = 8;
    private global::Tensorflow.Tpu.TPUEmbeddingOutputLayout outputLayout_;
    /// <summary>
    /// Extended output layout information; if not provided, a compatibility mode
    /// will use defaults that match the old layout. Providing a value for this
    /// field is EXPERIMENTAL and most ways of filling it will probably break. Do
    /// not set it unless you know what you are doing.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Tensorflow.Tpu.TPUEmbeddingOutputLayout OutputLayout {
      get { return outputLayout_; }
      set {
        outputLayout_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as TPUEmbeddingConfiguration);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(TPUEmbeddingConfiguration other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if(!tableDescriptor_.Equals(other.tableDescriptor_)) return false;
      if (Mode != other.Mode) return false;
      if (BatchSizePerTensorCore != other.BatchSizePerTensorCore) return false;
      if (NumHosts != other.NumHosts) return false;
      if (NumTensorCores != other.NumTensorCores) return false;
      if (ShardingStrategy != other.ShardingStrategy) return false;
      if (PipelineExecutionWithTensorCore != other.PipelineExecutionWithTensorCore) return false;
      if (!object.Equals(OutputLayout, other.OutputLayout)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      hash ^= tableDescriptor_.GetHashCode();
      if (Mode != 0) hash ^= Mode.GetHashCode();
      if (BatchSizePerTensorCore != 0) hash ^= BatchSizePerTensorCore.GetHashCode();
      if (NumHosts != 0) hash ^= NumHosts.GetHashCode();
      if (NumTensorCores != 0) hash ^= NumTensorCores.GetHashCode();
      if (ShardingStrategy != 0) hash ^= ShardingStrategy.GetHashCode();
      if (PipelineExecutionWithTensorCore != false) hash ^= PipelineExecutionWithTensorCore.GetHashCode();
      if (outputLayout_ != null) hash ^= OutputLayout.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      tableDescriptor_.WriteTo(output, _repeated_tableDescriptor_codec);
      if (Mode != 0) {
        output.WriteRawTag(16);
        output.WriteEnum((int) Mode);
      }
      if (BatchSizePerTensorCore != 0) {
        output.WriteRawTag(24);
        output.WriteInt32(BatchSizePerTensorCore);
      }
      if (NumHosts != 0) {
        output.WriteRawTag(32);
        output.WriteInt32(NumHosts);
      }
      if (NumTensorCores != 0) {
        output.WriteRawTag(40);
        output.WriteInt32(NumTensorCores);
      }
      if (ShardingStrategy != 0) {
        output.WriteRawTag(48);
        output.WriteEnum((int) ShardingStrategy);
      }
      if (PipelineExecutionWithTensorCore != false) {
        output.WriteRawTag(56);
        output.WriteBool(PipelineExecutionWithTensorCore);
      }
      if (outputLayout_ != null) {
        output.WriteRawTag(66);
        output.WriteMessage(OutputLayout);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      size += tableDescriptor_.CalculateSize(_repeated_tableDescriptor_codec);
      if (Mode != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) Mode);
      }
      if (BatchSizePerTensorCore != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(BatchSizePerTensorCore);
      }
      if (NumHosts != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumHosts);
      }
      if (NumTensorCores != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumTensorCores);
      }
      if (ShardingStrategy != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) ShardingStrategy);
      }
      if (PipelineExecutionWithTensorCore != false) {
        size += 1 + 1;
      }
      if (outputLayout_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(OutputLayout);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(TPUEmbeddingConfiguration other) {
      if (other == null) {
        return;
      }
      tableDescriptor_.Add(other.tableDescriptor_);
      if (other.Mode != 0) {
        Mode = other.Mode;
      }
      if (other.BatchSizePerTensorCore != 0) {
        BatchSizePerTensorCore = other.BatchSizePerTensorCore;
      }
      if (other.NumHosts != 0) {
        NumHosts = other.NumHosts;
      }
      if (other.NumTensorCores != 0) {
        NumTensorCores = other.NumTensorCores;
      }
      if (other.ShardingStrategy != 0) {
        ShardingStrategy = other.ShardingStrategy;
      }
      if (other.PipelineExecutionWithTensorCore != false) {
        PipelineExecutionWithTensorCore = other.PipelineExecutionWithTensorCore;
      }
      if (other.outputLayout_ != null) {
        if (outputLayout_ == null) {
          OutputLayout = new global::Tensorflow.Tpu.TPUEmbeddingOutputLayout();
        }
        OutputLayout.MergeFrom(other.OutputLayout);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            tableDescriptor_.AddEntriesFrom(input, _repeated_tableDescriptor_codec);
            break;
          }
          case 16: {
            Mode = (global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.Mode) input.ReadEnum();
            break;
          }
          case 24: {
            BatchSizePerTensorCore = input.ReadInt32();
            break;
          }
          case 32: {
            NumHosts = input.ReadInt32();
            break;
          }
          case 40: {
            NumTensorCores = input.ReadInt32();
            break;
          }
          case 48: {
            ShardingStrategy = (global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Types.ShardingStrategy) input.ReadEnum();
            break;
          }
          case 56: {
            PipelineExecutionWithTensorCore = input.ReadBool();
            break;
          }
          case 66: {
            if (outputLayout_ == null) {
              OutputLayout = new global::Tensorflow.Tpu.TPUEmbeddingOutputLayout();
            }
            input.ReadMessage(OutputLayout);
            break;
          }
        }
      }
    }

    #region Nested types
    /// <summary>Container for nested types declared in the TPUEmbeddingConfiguration message type.</summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static partial class Types {
      /// <summary>
      /// Mode. Should the embedding layer program be run for inference (just forward
      /// pass), training (both forward and backward pass) or just the backward_pass.
      /// </summary>
      public enum Mode {
        [pbr::OriginalName("UNSPECIFIED")] Unspecified = 0,
        [pbr::OriginalName("INFERENCE")] Inference = 1,
        [pbr::OriginalName("TRAINING")] Training = 2,
        [pbr::OriginalName("BACKWARD_PASS_ONLY")] BackwardPassOnly = 3,
      }

      /// <summary>
      /// Sharding strategy of the embedding tables among the hosts.
      /// If the sharding_strategy is "mod", each id is assigned to host
      /// "id % num_hosts". For instance, 13 ids are split across 5 hosts as:
      /// [[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]].
      /// If the sharding_strategy is "div", ids are assigned to hosts in a
      /// contiguous manner. In this case, 13 ids are split across 5 hosts as:
      /// [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]].
      /// In both the strategies, if the id space does not evenly divide the number
      /// of hosts, each of the first "table_descriptor.vocabulary_size % num_hosts"
      /// hosts will be assigned one more id.
      /// This partitioning strategy exactly follows that in the embedding_lookup
      /// TensorFlow function at tensorflow/python/ops/embedding_ops.py.
      /// </summary>
      public enum ShardingStrategy {
        [pbr::OriginalName("DIV_DEFAULT")] DivDefault = 0,
        [pbr::OriginalName("MOD")] Mod = 1,
      }

      /// <summary>
      /// Description of the various embedding tables.
      /// </summary>
      public sealed partial class TableDescriptor : pb::IMessage<TableDescriptor> {
        private static readonly pb::MessageParser<TableDescriptor> _parser = new pb::MessageParser<TableDescriptor>(() => new TableDescriptor());
        private pb::UnknownFieldSet _unknownFields;
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public static pb::MessageParser<TableDescriptor> Parser { get { return _parser; } }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public static pbr::MessageDescriptor Descriptor {
          get { return global::Tensorflow.Tpu.TPUEmbeddingConfiguration.Descriptor.NestedTypes[0]; }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        pbr::MessageDescriptor pb::IMessage.Descriptor {
          get { return Descriptor; }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public TableDescriptor() {
          OnConstruction();
        }

        partial void OnConstruction();

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public TableDescriptor(TableDescriptor other) : this() {
          name_ = other.name_;
          vocabularySize_ = other.vocabularySize_;
          dimension_ = other.dimension_;
          numFeatures_ = other.numFeatures_;
          optimizationParameters_ = other.optimizationParameters_ != null ? other.optimizationParameters_.Clone() : null;
          _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public TableDescriptor Clone() {
          return new TableDescriptor(this);
        }

        /// <summary>Field number for the "name" field.</summary>
        public const int NameFieldNumber = 1;
        private string name_ = "";
        /// <summary>
        /// Name of the table.
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public string Name {
          get { return name_; }
          set {
            name_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
          }
        }

        /// <summary>Field number for the "vocabulary_size" field.</summary>
        public const int VocabularySizeFieldNumber = 2;
        private int vocabularySize_;
        /// <summary>
        /// Size of the vocabulary (i.e., number of rows) in the table.
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public int VocabularySize {
          get { return vocabularySize_; }
          set {
            vocabularySize_ = value;
          }
        }

        /// <summary>Field number for the "dimension" field.</summary>
        public const int DimensionFieldNumber = 3;
        private int dimension_;
        /// <summary>
        /// The embedding dimension (i.e., the width of the embedding table).
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public int Dimension {
          get { return dimension_; }
          set {
            dimension_ = value;
          }
        }

        /// <summary>Field number for the "num_features" field.</summary>
        public const int NumFeaturesFieldNumber = 4;
        private int numFeatures_;
        /// <summary>
        /// Number of features mapped to this table.
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public int NumFeatures {
          get { return numFeatures_; }
          set {
            numFeatures_ = value;
          }
        }

        /// <summary>Field number for the "optimization_parameters" field.</summary>
        public const int OptimizationParametersFieldNumber = 5;
        private global::Tensorflow.Tpu.OptimizationParameters optimizationParameters_;
        /// <summary>
        /// Details of the learning algorithm used to update the embedding
        /// parameters.
        /// </summary>
        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public global::Tensorflow.Tpu.OptimizationParameters OptimizationParameters {
          get { return optimizationParameters_; }
          set {
            optimizationParameters_ = value;
          }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override bool Equals(object other) {
          return Equals(other as TableDescriptor);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public bool Equals(TableDescriptor other) {
          if (ReferenceEquals(other, null)) {
            return false;
          }
          if (ReferenceEquals(other, this)) {
            return true;
          }
          if (Name != other.Name) return false;
          if (VocabularySize != other.VocabularySize) return false;
          if (Dimension != other.Dimension) return false;
          if (NumFeatures != other.NumFeatures) return false;
          if (!object.Equals(OptimizationParameters, other.OptimizationParameters)) return false;
          return Equals(_unknownFields, other._unknownFields);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override int GetHashCode() {
          int hash = 1;
          if (Name.Length != 0) hash ^= Name.GetHashCode();
          if (VocabularySize != 0) hash ^= VocabularySize.GetHashCode();
          if (Dimension != 0) hash ^= Dimension.GetHashCode();
          if (NumFeatures != 0) hash ^= NumFeatures.GetHashCode();
          if (optimizationParameters_ != null) hash ^= OptimizationParameters.GetHashCode();
          if (_unknownFields != null) {
            hash ^= _unknownFields.GetHashCode();
          }
          return hash;
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public override string ToString() {
          return pb::JsonFormatter.ToDiagnosticString(this);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void WriteTo(pb::CodedOutputStream output) {
          if (Name.Length != 0) {
            output.WriteRawTag(10);
            output.WriteString(Name);
          }
          if (VocabularySize != 0) {
            output.WriteRawTag(16);
            output.WriteInt32(VocabularySize);
          }
          if (Dimension != 0) {
            output.WriteRawTag(24);
            output.WriteInt32(Dimension);
          }
          if (NumFeatures != 0) {
            output.WriteRawTag(32);
            output.WriteInt32(NumFeatures);
          }
          if (optimizationParameters_ != null) {
            output.WriteRawTag(42);
            output.WriteMessage(OptimizationParameters);
          }
          if (_unknownFields != null) {
            _unknownFields.WriteTo(output);
          }
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public int CalculateSize() {
          int size = 0;
          if (Name.Length != 0) {
            size += 1 + pb::CodedOutputStream.ComputeStringSize(Name);
          }
          if (VocabularySize != 0) {
            size += 1 + pb::CodedOutputStream.ComputeInt32Size(VocabularySize);
          }
          if (Dimension != 0) {
            size += 1 + pb::CodedOutputStream.ComputeInt32Size(Dimension);
          }
          if (NumFeatures != 0) {
            size += 1 + pb::CodedOutputStream.ComputeInt32Size(NumFeatures);
          }
          if (optimizationParameters_ != null) {
            size += 1 + pb::CodedOutputStream.ComputeMessageSize(OptimizationParameters);
          }
          if (_unknownFields != null) {
            size += _unknownFields.CalculateSize();
          }
          return size;
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void MergeFrom(TableDescriptor other) {
          if (other == null) {
            return;
          }
          if (other.Name.Length != 0) {
            Name = other.Name;
          }
          if (other.VocabularySize != 0) {
            VocabularySize = other.VocabularySize;
          }
          if (other.Dimension != 0) {
            Dimension = other.Dimension;
          }
          if (other.NumFeatures != 0) {
            NumFeatures = other.NumFeatures;
          }
          if (other.optimizationParameters_ != null) {
            if (optimizationParameters_ == null) {
              OptimizationParameters = new global::Tensorflow.Tpu.OptimizationParameters();
            }
            OptimizationParameters.MergeFrom(other.OptimizationParameters);
          }
          _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
        }

        [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
        public void MergeFrom(pb::CodedInputStream input) {
          uint tag;
          while ((tag = input.ReadTag()) != 0) {
            switch(tag) {
              default:
                _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
                break;
              case 10: {
                Name = input.ReadString();
                break;
              }
              case 16: {
                VocabularySize = input.ReadInt32();
                break;
              }
              case 24: {
                Dimension = input.ReadInt32();
                break;
              }
              case 32: {
                NumFeatures = input.ReadInt32();
                break;
              }
              case 42: {
                if (optimizationParameters_ == null) {
                  OptimizationParameters = new global::Tensorflow.Tpu.OptimizationParameters();
                }
                input.ReadMessage(OptimizationParameters);
                break;
              }
            }
          }
        }

      }

    }
    #endregion

  }

  #endregion

}

#endregion Designer generated code
